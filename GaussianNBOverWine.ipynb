{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GaussianNBOverWine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0ORdlj+YwuWJ6juL3uVO8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawanGithub10/MachineLearning/blob/main/GaussianNBOverWine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyUk_Y4S2mav",
        "outputId": "c4121453-8dfc-435c-a280-21cbdb5819a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAkKjofg2uZr",
        "outputId": "12c15bbd-c9f6-4754-fb34-817d24fd19cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò.kaggle‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSexNQfw22Bx"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"pawanbhakuni\",\"key\":\"d9b555981b6526229d28c18c901cd384\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF7NKEkb4QBF"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1BZNhw4ony",
        "outputId": "0aeb246f-7e44-42bd-dad9-290bd79c4712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J11G6G6q5g1x",
        "outputId": "4fd394a6-b542-4042-bbbe-8419cfc7f37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw_hpO5_5naq"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83yl_jY5r0p",
        "outputId": "81db7876-195b-4190-c458-7042fa8c3a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                               title                                                 size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------------  --------------------------------------------------  ------  -------------------  -------------  \n",
            "heeraldedhia/groceries-dataset                                    Groceries dataset                                    257KB  2020-09-17 04:36:08           1292  \n",
            "andrewmvd/trip-advisor-hotel-reviews                              Trip Advisor Hotel Reviews                             5MB  2020-09-30 08:31:20            759  \n",
            "balraj98/stanford-background-dataset                              Stanford Background Dataset                           17MB  2020-09-26 12:57:59             94  \n",
            "nehaprabhavalkar/indian-food-101                                  Indian Food 101                                        7KB  2020-09-30 06:23:43           1146  \n",
            "christianlillelund/donald-trumps-rallies                          Donald Trump's Rallies                               720KB  2020-09-26 10:25:08            199  \n",
            "jilkothari/finance-accounting-courses-udemy-13k-course            Finance & Accounting Courses - Udemy (13K+ course)  1000KB  2020-09-17 12:46:12            349  \n",
            "balraj98/massachusetts-roads-dataset                              Massachusetts Roads Dataset                            6GB  2020-09-26 03:57:49             64  \n",
            "arslanali4343/top-personality-dataset                             Top Personality Dataset                                9MB  2020-09-27 21:25:45            372  \n",
            "oldaandozerskaya/fiction-corpus-for-agebased-text-classification  RusAge: Corpus for Age-Based Text Classification     509MB  2020-09-28 09:30:12             19  \n",
            "gpreda/chinese-mnist                                              Chinese MNIST                                         10MB  2020-08-05 12:36:00            160  \n",
            "gpreda/local-elections-romania-2020                               Local Elections Romania 2020                          28MB  2020-09-27 20:46:11             68  \n",
            "anth7310/mental-health-in-the-tech-industry                       Mental Health in the Tech Industry                     2MB  2020-09-27 11:17:23            539  \n",
            "roshansharma/sanfranciso-crime-dataset                            Sanfranciso Crime Dataset                              6MB  2019-05-29 12:45:44           3200  \n",
            "bppuneethpai/tldr-summary-for-man-pages                           TLDR summary for man pages                             8MB  2020-09-25 09:50:10             12  \n",
            "sterby/german-recipes-dataset                                     German Recipes Dataset                                 5MB  2019-03-06 16:25:22            776  \n",
            "arslanali4343/real-estate-dataset                                 Real Estate DataSet                                   12KB  2020-09-28 21:25:33            431  \n",
            "thomaskonstantin/top-270-rated-computer-science-programing-books  Top 270 Computer Science / Programing Books           45KB  2020-09-28 16:47:12            215  \n",
            "leangab/poe-short-stories-corpuscsv                               E.A. Poe's corpus of short stories                   725KB  2020-09-28 11:43:08             56  \n",
            "anmolkumar/health-insurance-cross-sell-prediction                 Health Insurance Cross Sell Prediction üè† üè•             6MB  2020-09-11 18:39:31           3619  \n",
            "ramjidoolla/ipl-data-set                                          IPL _Data_Set                                          1MB  2020-09-14 10:57:42           3087  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MEufxdZ50QC",
        "outputId": "b7f56d4a-f8fc-45a8-811e-22a599de7081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!kaggle datasets list -s titanic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                 title                                           size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  \n",
            "heptapod/titanic                                    Titanic                                         11KB  2017-05-16 08:14:22          14824  \n",
            "azeembootwala/titanic                               Titanic                                         12KB  2017-06-05 12:14:37           6758  \n",
            "prkukunoor/TitanicDataset                           Titanic                                        135KB  2017-01-03 22:01:13           3381  \n",
            "broaniki/titanic                                    titanic                                        717KB  2018-01-30 04:08:45           7309  \n",
            "hesh97/titanicdataset-traincsv                      Titanic-Dataset (train.csv)                     22KB  2018-02-02 04:51:06          27349  \n",
            "kittisaks/testtitanic                               test titanic                                    22KB  2017-03-13 15:13:12           1327  \n",
            "fossouodonald/titaniccsv                            Titanic csv                                      1KB  2016-11-07 09:44:58           5259  \n",
            "jamesleslie/titanic-cleaned-data                    Titanic: cleaned data                           36KB  2018-11-21 11:50:18           2355  \n",
            "pavlofesenko/titanic-extended                       Titanic extended dataset (Kaggle + Wikipedia)  134KB  2019-03-06 09:53:24           3661  \n",
            "rahulsah06/titanic                                  Titanic                                         34KB  2019-09-16 14:43:23            257  \n",
            "abhinavralhan/titanic                               titanic                                         22KB  2017-07-30 11:07:55            440  \n",
            "cities/titanic123                                   Titanic Dataset Analysis                        22KB  2017-02-07 23:15:54            924  \n",
            "harunshimanto/titanic-solution-for-beginners-guide  Titanic Solution for Beginner's Guide           34KB  2018-03-12 17:47:06            918  \n",
            "sureshbhusare/titanic-dataset-from-kaggle           Titanic DataSet from Kaggle                     33KB  2017-10-12 04:49:39           1674  \n",
            "mahdijavid/datacamptraining                         DataCampTraining(Titanic)                        1KB  2017-01-05 11:36:30            167  \n",
            "rganapathy/titanic-subset                           Titanic subset                                  22KB  2017-05-11 04:30:37            317  \n",
            "davorbudimir/titanic                                Titanic                                         485B  2020-04-19 13:14:12             13  \n",
            "shuofxz/titanic-machine-learning-from-disaster      Titanic: Machine Learning from Disaster         33KB  2017-10-15 10:05:34           1146  \n",
            "dushyantkhinchi/titanic-survival                    Titanic survival                                33KB  2018-01-21 09:24:33            531  \n",
            "tedllh/titanic-train                                titanic_train                                   22KB  2018-02-23 07:13:19           1886  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2DZ1ais67mm",
        "outputId": "ce22c072-ec27-4de4-b9f2-fbea28e681fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle datasets download -d shuofxz/titanic-machine-learning-from-disaster -p /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "titanic-machine-learning-from-disaster.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw138cgZ7LPa",
        "outputId": "04d5ef60-2761-40f9-97ef-bfafb069704c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  titanic-machine-learning-from-disaster.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: test.csv                \n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  red-wine-quality-cortez-et-al-2009.zip\n",
            "replace winequality-red.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: winequality-red.csv     \n",
            "\n",
            "2 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFA_ssi27QN6",
        "outputId": "a21bbb7e-3fc9-49cd-cad7-8bf062250d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head(100)\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyCYWg2znWKF",
        "outputId": "cef35f64-19e5-4971-a908-fc842bee163e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#Pearson Correlation Coefficient\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "df.corr(method ='pearson') \n",
        "#sns.heatmap(df, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005007</td>\n",
              "      <td>-0.035144</td>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.012658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>-0.005007</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.257307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>-0.035144</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>-0.549500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.096067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>0.159651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.257307</td>\n",
              "      <td>-0.549500</td>\n",
              "      <td>0.096067</td>\n",
              "      <td>0.159651</td>\n",
              "      <td>0.216225</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PassengerId  Survived    Pclass  ...     SibSp     Parch      Fare\n",
              "PassengerId     1.000000 -0.005007 -0.035144  ... -0.057527 -0.001652  0.012658\n",
              "Survived       -0.005007  1.000000 -0.338481  ... -0.035322  0.081629  0.257307\n",
              "Pclass         -0.035144 -0.338481  1.000000  ...  0.083081  0.018443 -0.549500\n",
              "Age             0.036847 -0.077221 -0.369226  ... -0.308247 -0.189119  0.096067\n",
              "SibSp          -0.057527 -0.035322  0.083081  ...  1.000000  0.414838  0.159651\n",
              "Parch          -0.001652  0.081629  0.018443  ...  0.414838  1.000000  0.216225\n",
              "Fare            0.012658  0.257307 -0.549500  ...  0.159651  0.216225  1.000000\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs7LM0kDnPaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNr_JHiZ7lyY"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "train,test = train_test_split(df,test_size=0.2)\n",
        "#print(type(train))\n",
        "#print(test)\n",
        "X_train =  train.iloc[:,0:11]\n",
        "y_train =  train.iloc[:,11]\n",
        "X_test  =  test.iloc[:,0:11]\n",
        "y_test  =  test.iloc[:,11]\n",
        "#print(xTrain)\n",
        "#print(yTrain)\n",
        "#print(xTest)\n",
        "#print(yTest)\n",
        "\n",
        "\n",
        "gnbClassify = GaussianNB()\n",
        "gnbClassify.fit(X_train,y_train)\n",
        "y_predicted = gnbClassify.predict(X_test)\n",
        "accuracy_score(y_test,y_predicted)\n",
        "\n",
        "# decisionTree = tree.DecisionTreeClassifier(max_leaf_nodes=40)\n",
        "# decisionTree.fit(X_train,y_train)\n",
        "# y_predicted = gnbClassify.predict(X_test)\n",
        "# accuracy_score(y_test,y_predicted)\n",
        "\n",
        "# linearRegression = tree.DecisionTreeClassifier(max_leaf_nodes=40)\n",
        "# linearRegression.fit(X_train,y_train)\n",
        "# y_predicted = gnbClassify.predict(X_test)\n",
        "# accuracy_score(y_test,y_predicted)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}